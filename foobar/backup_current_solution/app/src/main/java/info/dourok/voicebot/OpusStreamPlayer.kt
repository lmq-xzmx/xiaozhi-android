package info.dourok.voicebot

import android.media.AudioAttributes
import android.media.AudioFormat
import android.media.AudioTrack
import android.util.Log
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.cancel
import kotlinx.coroutines.delay
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.collect
import kotlinx.coroutines.launch
import kotlinx.coroutines.sync.Mutex
import kotlinx.coroutines.sync.withLock
import kotlinx.coroutines.SupervisorJob
import kotlinx.coroutines.CancellationException
import kotlinx.coroutines.NonCancellable
import kotlinx.coroutines.ensureActive
import kotlinx.coroutines.withContext
import kotlinx.coroutines.runBlocking

/**
 * ESP32å…¼å®¹çš„å®æ—¶éŸ³é¢‘æ’­æ”¾å™¨
 * å®Œå…¨æ¨¡æ‹ŸESP32ç«¯çš„I2Så®æ—¶æ’­æ”¾æœºåˆ¶ï¼Œæ— ç¼“å†²å»¶è¿Ÿ
 */
class OpusStreamPlayer(
    private val sampleRate: Int,
    private val channels: Int,
    frameSizeMs: Int
) {
    companion object {
        private const val TAG = "OpusStreamPlayer"
        
        // ESP32å…¼å®¹å‚æ•°
        private const val FRAME_DURATION_MS = 60L // ESP32ä½¿ç”¨60mså¸§
        private const val SAMPLES_PER_FRAME = 960 // 16kHz * 60ms = 960 samples
        private const val BYTES_PER_SAMPLE = 2    // 16-bit PCM = 2 bytes
        private const val FRAME_SIZE_BYTES = SAMPLES_PER_FRAME * BYTES_PER_SAMPLE // 1920 bytes
        
        // æœ€å°ç¡¬ä»¶ç¼“å†²ï¼Œæ¨¡æ‹ŸI2Sç¡¬ä»¶ç¼“å†²
        private const val MIN_HARDWARE_BUFFER_FRAMES = 2 // åªä¿ç•™2å¸§çš„ç¡¬ä»¶ç¼“å†²
    }

    private var audioTrack: AudioTrack
    private val playerScope = CoroutineScope(Dispatchers.IO + SupervisorJob())
    private var isStreaming = false
    private val mutex = Mutex()
    
    // ESP32æ¨¡æ‹Ÿï¼šå®æ—¶æ’­æ”¾ç»Ÿè®¡
    private var framesReceived = 0
    private var framesPlayed = 0
    private var playbackStartTime = 0L

    init {
        val channelConfig = if (channels == 1) AudioFormat.CHANNEL_OUT_MONO else AudioFormat.CHANNEL_OUT_STEREO
        
        // ESP32å…¼å®¹ï¼šæœ€å°ç¼“å†²åŒºé…ç½®ï¼Œæ¨¡æ‹ŸI2Sç¡¬ä»¶ç¼“å†²
        val minBufferSize = AudioTrack.getMinBufferSize(
            sampleRate,
            channelConfig,
            AudioFormat.ENCODING_PCM_16BIT
        )
        
        // åªä½¿ç”¨æœ€å°ç¼“å†²åŒºå¤§å°ï¼Œæ¨¡æ‹ŸESP32çš„I2Sç¡¬ä»¶ç¼“å†²
        val bufferSize = maxOf(minBufferSize, FRAME_SIZE_BYTES * MIN_HARDWARE_BUFFER_FRAMES)

        audioTrack = AudioTrack.Builder()
            .setAudioAttributes(
                AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
                    .build()
            )
            .setAudioFormat(
                AudioFormat.Builder()
                    .setSampleRate(sampleRate)
                    .setChannelMask(channelConfig)
                    .setEncoding(AudioFormat.ENCODING_PCM_16BIT)
                    .build()
            )
            .setBufferSizeInBytes(bufferSize)
            .setTransferMode(AudioTrack.MODE_STREAM)
            .build()
        
        Log.i(TAG, "ESP32å…¼å®¹æ’­æ”¾å™¨åˆå§‹åŒ–: sampleRate=$sampleRate, channels=$channels, bufferSize=$bufferSize, æœ€å°å»¶è¿Ÿæ¨¡å¼")
    }

    /**
     * ESP32å…¼å®¹ï¼šå¯åŠ¨å®æ—¶æµå¼æ’­æ”¾
     * æ¨¡æ‹ŸESP32çš„I2Så®æ—¶æ¥æ”¶å’Œæ’­æ”¾æœºåˆ¶
     */
    fun start(pcmFlow: Flow<ByteArray?>) {
        playerScope.launch {
            try {
                mutex.withLock {
                    if (isStreaming) {
                        Log.w(TAG, "å®æ—¶æ’­æ”¾å·²åœ¨è¿è¡Œï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
                        return@withLock
                    }
                    
                    isStreaming = true
                    framesReceived = 0
                    framesPlayed = 0
                    playbackStartTime = System.currentTimeMillis()
                    
                    Log.i(TAG, "ğŸµ å¯åŠ¨ESP32å…¼å®¹å®æ—¶éŸ³é¢‘æ’­æ”¾...")
                    
                    // å¯åŠ¨AudioTrack
            if (audioTrack.state == AudioTrack.STATE_INITIALIZED) {
                audioTrack.play()
                        Log.i(TAG, "AudioTrackå¯åŠ¨æˆåŠŸï¼Œè¿›å…¥å®æ—¶æ’­æ”¾æ¨¡å¼")
                    } else {
                        Log.e(TAG, "AudioTrackåˆå§‹åŒ–å¤±è´¥")
                        return@withLock
                    }
            }

                // ESP32å…¼å®¹ï¼šå®æ—¶å¤„ç†æ¯ä¸ªéŸ³é¢‘å¸§
                try {
                pcmFlow.collect { pcmData ->
                        // æ£€æŸ¥åç¨‹æ˜¯å¦è¢«å–æ¶ˆ
                        ensureActive()
                        
                        pcmData?.let { data ->
                            if (isStreaming) {
                                processRealtimeAudioFrame(data)
                            }
                        }
                    }
                } catch (e: CancellationException) {
                    Log.i(TAG, "éŸ³é¢‘æ’­æ”¾æµè¢«æ­£å¸¸å–æ¶ˆ")
                    throw e
                } catch (e: Exception) {
                    Log.e(TAG, "éŸ³é¢‘æ’­æ”¾æµå‘ç”Ÿå¼‚å¸¸", e)
                    throw e
                }
                
            } catch (e: CancellationException) {
                Log.i(TAG, "ESP32å®æ—¶æ’­æ”¾è¢«å–æ¶ˆ")
                // åç¨‹å–æ¶ˆæ˜¯æ­£å¸¸çš„ï¼Œä¸éœ€è¦æŠ¥å‘Šä¸ºé”™è¯¯
            } catch (e: Exception) {
                Log.e(TAG, "ESP32å®æ—¶æ’­æ”¾å¤±è´¥", e)
            } finally {
                // å®‰å…¨æ¸…ç†èµ„æº
                try {
                    withContext(NonCancellable) {
                        mutex.withLock {
                            isStreaming = false
                            if (audioTrack.state == AudioTrack.STATE_INITIALIZED) {
                                audioTrack.stop()
                                Log.i(TAG, "AudioTrackå·²å®‰å…¨åœæ­¢")
                            }
                        }
                    }
                        } catch (e: Exception) {
                    Log.e(TAG, "æ¸…ç†æ’­æ”¾èµ„æºæ—¶å‘ç”Ÿå¼‚å¸¸", e)
                }
            }
        }
    }
    
    /**
     * ESP32å…¼å®¹ï¼šå®æ—¶å¤„ç†éŸ³é¢‘å¸§
     * æ¨¡æ‹ŸESP32æ¥æ”¶OpusåŒ…åç«‹å³è§£ç å¹¶å†™å…¥I2Sçš„è¿‡ç¨‹
     */
    private suspend fun processRealtimeAudioFrame(pcmData: ByteArray) {
        if (!isStreaming || audioTrack.state != AudioTrack.STATE_INITIALIZED) {
            return
        }
        
        try {
            framesReceived++
            
            // ESP32å…¼å®¹ï¼šç›´æ¥å†™å…¥AudioTrackï¼Œæ¨¡æ‹ŸI2Sç›´æ¥æ’­æ”¾
            val bytesWritten = audioTrack.write(pcmData, 0, pcmData.size)
            
            if (bytesWritten > 0) {
                framesPlayed++
                
                Log.d(TAG, "å®æ—¶æ’­æ”¾å¸§ #$framesPlayed: å†™å…¥${bytesWritten}å­—èŠ‚ (æ¥æ”¶#$framesReceived)")
                
                // ESP32å…¼å®¹ï¼šæŒ‰60mså¸§é—´éš”æ§åˆ¶æ’­æ”¾èŠ‚å¥
                // è¿™é‡Œä¸éœ€è¦sleepï¼Œå› ä¸ºAudioTrackçš„å†…éƒ¨ç¼“å†²ä¼šæ§åˆ¶æ’­æ”¾é€Ÿåº¦
                // è¿™æ ·æ‰èƒ½çœŸæ­£æ¨¡æ‹ŸESP32çš„I2Så®æ—¶æ’­æ”¾
                
            } else if (bytesWritten < 0) {
                Log.e(TAG, "AudioTrackå†™å…¥å¤±è´¥: $bytesWritten")
                
                // ESP32å…¼å®¹ï¼šå†™å…¥å¤±è´¥æ—¶çš„å¤„ç†ç­–ç•¥
                when (bytesWritten) {
                    AudioTrack.ERROR_INVALID_OPERATION -> {
                        Log.e(TAG, "AudioTrackå¤„äºæ— æ•ˆçŠ¶æ€")
                    }
                    AudioTrack.ERROR_BAD_VALUE -> {
                        Log.e(TAG, "AudioTrackå‚æ•°é”™è¯¯")
                        }
                    AudioTrack.ERROR_DEAD_OBJECT -> {
                        Log.e(TAG, "AudioTrackå¯¹è±¡å·²æ­»äº¡ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–")
                        // è¿™é‡Œå¯ä»¥å°è¯•é‡æ–°åˆå§‹åŒ–AudioTrack
                    }
                    else -> {
                        Log.e(TAG, "æœªçŸ¥çš„AudioTracké”™è¯¯: $bytesWritten")
                }
            }
            } else {
                Log.w(TAG, "AudioTrackå†™å…¥è¿”å›0ï¼Œå¯èƒ½ç¼“å†²åŒºå·²æ»¡")
                
                // ESP32å…¼å®¹ï¼šå¦‚æœAudioTrackç¼“å†²åŒºæ»¡äº†ï¼Œç¨ç­‰ä¸€ä¸‹å†ç»§ç»­
                // è¿™æ¨¡æ‹Ÿäº†ESP32çš„I2Så½“ç¡¬ä»¶ç¼“å†²æ»¡æ—¶çš„è¡Œä¸º
                delay(5) // çŸ­æš‚å»¶è¿Ÿ5ms
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "å®æ—¶éŸ³é¢‘å¸§å¤„ç†å¤±è´¥", e)
        }
    }

    /**
     * ESP32å…¼å®¹ï¼šåœæ­¢å®æ—¶æ’­æ”¾
     */
    fun stop() {
        playerScope.launch {
            try {
                mutex.withLock {
                    if (!isStreaming) return@withLock
                    
                    Log.i(TAG, "ğŸ›‘ åœæ­¢ESP32å…¼å®¹å®æ—¶æ’­æ”¾...")
                    isStreaming = false
                    
            if (audioTrack.state == AudioTrack.STATE_INITIALIZED) {
                        // ESP32å…¼å®¹ï¼šåœæ­¢æ’­æ”¾ï¼Œä½†è®©å·²æœ‰çš„éŸ³é¢‘æ’­æ”¾å®Œæ¯•
                audioTrack.stop()
                        Log.i(TAG, "AudioTrackå·²åœæ­¢")
                    }
                    
                    // ESP32å…¼å®¹ï¼šè¾“å‡ºæ’­æ”¾ç»Ÿè®¡ä¿¡æ¯
                    val totalDuration = System.currentTimeMillis() - playbackStartTime
                    Log.i(TAG, "æ’­æ”¾ç»Ÿè®¡: æ¥æ”¶å¸§æ•°=$framesReceived, æ’­æ”¾å¸§æ•°=$framesPlayed, æ€»æ—¶é•¿=${totalDuration}ms")
                }
            } catch (e: Exception) {
                Log.e(TAG, "åœæ­¢æ’­æ”¾æ—¶å‘ç”Ÿå¼‚å¸¸", e)
            }
        }
    }

    /**
     * é‡Šæ”¾æ‰€æœ‰èµ„æº
     */
    fun release() {
        try {
            // é¦–å…ˆåœæ­¢æ’­æ”¾
            runBlocking {
                withContext(NonCancellable) {
                    mutex.withLock {
                        isStreaming = false
                        if (audioTrack.state == AudioTrack.STATE_INITIALIZED) {
                            audioTrack.stop()
                        }
                    }
                }
            }
            
            // å–æ¶ˆåç¨‹ä½œç”¨åŸŸ
            playerScope.cancel()
            
            // é‡Šæ”¾AudioTrack
        audioTrack.release()
            Log.i(TAG, "ESP32å…¼å®¹æ’­æ”¾å™¨èµ„æºå·²é‡Šæ”¾")
            
        } catch (e: Exception) {
            Log.e(TAG, "é‡Šæ”¾æ’­æ”¾å™¨èµ„æºæ—¶å‘ç”Ÿå¼‚å¸¸", e)
        }
    }

    /**
     * ESP32å…¼å®¹ï¼šç­‰å¾…æ’­æ”¾å®Œæˆ
     * æ¨¡æ‹ŸESP32ç­‰å¾…I2Sç¡¬ä»¶ç¼“å†²åŒºæ’­æ”¾å®Œæ¯•çš„è¿‡ç¨‹
     */
    suspend fun waitForPlaybackCompletion() {
        if (!isStreaming) {
            Log.d(TAG, "æ’­æ”¾å™¨æœªè¿è¡Œï¼Œæ— éœ€ç­‰å¾…")
            return
        }
        
        Log.i(TAG, "ç­‰å¾…å®æ—¶æ’­æ”¾å®Œæˆ...")
        
        // ESP32å…¼å®¹ï¼šæ£€æŸ¥AudioTrackçš„æ’­æ”¾å¤´ä½ç½®
        var previousPosition = audioTrack.playbackHeadPosition
        var stableCount = 0
        val maxStableChecks = 5 // æœ€å¤šæ£€æŸ¥5æ¬¡ç¨³å®šçŠ¶æ€
        val checkInterval = 100L // æ¯100msæ£€æŸ¥ä¸€æ¬¡
        
        while (audioTrack.playState == AudioTrack.PLAYSTATE_PLAYING && stableCount < maxStableChecks) {
            delay(checkInterval)
            
            val currentPosition = audioTrack.playbackHeadPosition
            if (currentPosition == previousPosition) {
                stableCount++
                Log.d(TAG, "æ’­æ”¾å¤´ä½ç½®ç¨³å®š #$stableCount: $currentPosition")
            } else {
                stableCount = 0
                previousPosition = currentPosition
                Log.d(TAG, "æ’­æ”¾å¤´ä½ç½®å˜åŒ–: $currentPosition")
            }
        }
        
        Log.i(TAG, "âœ… å®æ—¶æ’­æ”¾å®Œæˆç­‰å¾…ç»“æŸ")
    }
    
    /**
     * ESP32å…¼å®¹ï¼šè·å–æ’­æ”¾å™¨çŠ¶æ€ä¿¡æ¯
     */
    fun getPlaybackInfo(): String {
        return if (isStreaming) {
            val bufferPosition = audioTrack.playbackHeadPosition
            val playState = when (audioTrack.playState) {
                AudioTrack.PLAYSTATE_STOPPED -> "STOPPED"
                AudioTrack.PLAYSTATE_PAUSED -> "PAUSED"
                AudioTrack.PLAYSTATE_PLAYING -> "PLAYING"
                else -> "UNKNOWN"
            }
            "å®æ—¶æ’­æ”¾ä¸­: çŠ¶æ€=$playState, æ’­æ”¾ä½ç½®=$bufferPosition, æ¥æ”¶å¸§æ•°=$framesReceived, æ’­æ”¾å¸§æ•°=$framesPlayed"
        } else {
            "æ’­æ”¾å™¨å·²åœæ­¢"
        }
    }
}