# Androidç«¯ä¸ESP32ç«¯STTè§¦å‘æœºåˆ¶å®Œå…¨ç»Ÿä¸€è§£å†³æ–¹æ¡ˆ

## ğŸ¯ ç›®æ ‡ï¼šå®Œå…¨ç»Ÿä¸€STTè§¦å‘æµç¨‹

è®©Androidç«¯çš„STTè§¦å‘æœºåˆ¶ä¸ESP32ç«¯ä¿æŒå®Œå…¨ä¸€è‡´ï¼Œéƒ½é‡‡ç”¨**æœåŠ¡å™¨ç«¯VADè‡ªåŠ¨æ£€æµ‹è¯­éŸ³ç»“æŸè§¦å‘STT**çš„æ¨¡å¼ã€‚

## ğŸ“‹ å½“å‰ç°çŠ¶åˆ†æ

### ESP32ç«¯STTè§¦å‘æµç¨‹ï¼ˆæ ‡å‡†å‚è€ƒï¼‰
```python
# æœåŠ¡å™¨ç«¯ receiveAudioHandle.py
async def handleAudioMessage(conn, audio):
    # 1. æœåŠ¡å™¨ç«¯VADæ£€æµ‹
    have_voice = conn.vad.is_vad(conn, audio)
    
    # 2. ç´¯ç§¯éŸ³é¢‘æ•°æ®
    conn.asr_audio.append(audio)
    
    # 3. VADæ£€æµ‹è¯­éŸ³ç»“æŸï¼Œè‡ªåŠ¨è§¦å‘STT
    if conn.client_voice_stop:
        text, error = await conn.asr.speech_to_text(conn.asr_audio, conn.session_id)
        if text and len(text.strip()) > 0:
            await startToChat(conn, text)
```

### Androidç«¯å½“å‰STTè§¦å‘æµç¨‹
```kotlin
// ChatViewModel.kt - observeProtocolMessages()
"stt" -> {
    val text = json.optString("text")
    if (text.isNotEmpty()) {
        display.setChatMessage("user", text)
        // éœ€è¦æ‰‹åŠ¨çŠ¶æ€ç®¡ç†
    }
}
```

**é—®é¢˜è¯†åˆ«**ï¼š
- âœ… Androidç«¯å·²ä½¿ç”¨æœåŠ¡å™¨ç«¯VADï¼ˆéŸ³é¢‘æŒç»­å‘é€åˆ°æœåŠ¡å™¨ï¼‰
- âŒ Androidç«¯è¿˜éœ€è¦é¢å¤–çš„WebSocketæ¶ˆæ¯å¤„ç†å’ŒçŠ¶æ€ç®¡ç†
- âŒ æµç¨‹ä¸å¤Ÿçº¯ç²¹ï¼Œæœ‰é¢å¤–çš„å®¢æˆ·ç«¯é€»è¾‘

## ğŸš€ å®Œå…¨ç»Ÿä¸€è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šçº¯æœåŠ¡å™¨ç«¯é©±åŠ¨æ¨¡å¼ï¼ˆæ¨èï¼‰

#### 1.1 Androidç«¯æ”¹é€ 
**ç›®æ ‡**ï¼šè®©Androidç«¯å®Œå…¨ä¾èµ–æœåŠ¡å™¨ç«¯VADï¼Œç§»é™¤å®¢æˆ·ç«¯çŠ¶æ€åˆ¤æ–­

```kotlin
// æ”¹é€ åçš„ChatViewModel.kt
class ChatViewModel {
    // ç§»é™¤å¤æ‚çš„å®¢æˆ·ç«¯çŠ¶æ€ç®¡ç†
    // private var keepListening = false  // åˆ é™¤
    // private var isAudioFlowRunning = false  // åˆ é™¤
    
    /**
     * å¯åŠ¨ESP32å®Œå…¨å…¼å®¹çš„STTæ¨¡å¼
     * çº¯æœåŠ¡å™¨ç«¯VADé©±åŠ¨ï¼Œæ— å®¢æˆ·ç«¯çŠ¶æ€ç®¡ç†
     */
    fun startPureServerVadMode() {
        viewModelScope.launch {
            val currentProtocol = protocol
            if (currentProtocol == null) {
                Log.e(TAG, "Protocol not initialized")
                return@launch
            }
            
            Log.i(TAG, "ğŸš€ å¯åŠ¨çº¯æœåŠ¡å™¨ç«¯VADé©±åŠ¨æ¨¡å¼")
            
            // 1. æ‰“å¼€éŸ³é¢‘é€šé“
            if (!currentProtocol.isAudioChannelOpened()) {
                deviceState = DeviceState.CONNECTING
                if (!currentProtocol.openAudioChannel()) {
                    deviceState = DeviceState.IDLE
                    return@launch
                }
            }
            
            // 2. å¯åŠ¨ç›‘å¬ï¼ˆä¸ESP32å®Œå…¨ç›¸åŒï¼‰
            currentProtocol.sendStartListening(ListeningMode.AUTO_STOP)
            deviceState = DeviceState.LISTENING
            
            // 3. å¯åŠ¨çº¯éŸ³é¢‘æ•°æ®æµï¼ˆæ— çŠ¶æ€åˆ¤æ–­ï¼‰
            startPureAudioFlow(currentProtocol)
        }
    }
    
    /**
     * çº¯éŸ³é¢‘æ•°æ®æµ - ä¸ESP32ç«¯å®Œå…¨ä¸€è‡´
     * åªè´Ÿè´£å‘é€éŸ³é¢‘ï¼Œæ‰€æœ‰é€»è¾‘ç”±æœåŠ¡å™¨ç«¯å¤„ç†
     */
    private fun startPureAudioFlow(protocol: Protocol) {
        currentAudioJob = viewModelScope.launch(SupervisorJob()) {
            try {
                Log.i(TAG, "å¯åŠ¨çº¯éŸ³é¢‘æ•°æ®æµï¼ˆESP32æ¨¡å¼ï¼‰...")
                
                val currentRecorder = recorder
                val currentEncoder = encoder
                
                if (currentRecorder == null || currentEncoder == null) {
                    Log.e(TAG, "éŸ³é¢‘ç»„ä»¶æœªåˆå§‹åŒ–")
                    return@launch
                }
                
                // å¯åŠ¨æŒç»­å½•éŸ³
                withContext(Dispatchers.IO) {
                    val audioFlow = currentRecorder.startRecording()
                    
                    // çº¯éŸ³é¢‘å¤„ç† - æ— çŠ¶æ€åˆ¤æ–­
                    audioFlow.collect { pcmData ->
                        try {
                            // æ— æ¡ä»¶ç¼–ç å’Œå‘é€ï¼ˆä¸ESP32ä¸€è‡´ï¼‰
                            val opusData = currentEncoder.encode(pcmData)
                            if (opusData != null && opusData.isNotEmpty()) {
                                protocol.sendAudio(opusData)
                            }
                        } catch (e: Exception) {
                            Log.e(TAG, "éŸ³é¢‘å¤„ç†å¤±è´¥", e)
                        }
                    }
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "çº¯éŸ³é¢‘æµç¨‹å¤±è´¥", e)
            }
        }
    }
    
    /**
     * ç®€åŒ–çš„æ¶ˆæ¯å¤„ç† - å®Œå…¨ä¾èµ–æœåŠ¡å™¨ç«¯é€»è¾‘
     */
    private fun observeProtocolMessages() {
        viewModelScope.launch {
            protocol?.incomingJsonFlow?.collect { json ->
                val type = json.optString("type")
                when (type) {
                    "stt" -> {
                        // çº¯ç²¹çš„STTç»“æœå±•ç¤ºï¼Œæ— çŠ¶æ€ç®¡ç†
                        val text = json.optString("text")
                        if (text.isNotEmpty()) {
                            Log.i(TAG, "ğŸ¯ æœåŠ¡å™¨ç«¯VADè§¦å‘STTç»“æœ: '$text'")
                            display.setChatMessage("user", text)
                            // ä¸åšä»»ä½•çŠ¶æ€ç®¡ç†ï¼Œå®Œå…¨ä¾èµ–æœåŠ¡å™¨ç«¯
                        }
                    }
                    
                    "tts" -> {
                        val state = json.optString("state")
                        when (state) {
                            "start" -> {
                                // ç®€å•çš„æ’­æ”¾çŠ¶æ€æ›´æ–°
                                deviceState = DeviceState.SPEAKING
                                startTtsAudioPlayback()
                                // ç»§ç»­éŸ³é¢‘æµï¼Œè®©æœåŠ¡å™¨ç«¯VADå¤„ç†æ‰“æ–­
                            }
                            
                            "stop" -> {
                                // TTSç»“æŸï¼Œè‡ªåŠ¨æ¢å¤ç›‘å¬
                                stopTtsAudioPlayback()
                                deviceState = DeviceState.LISTENING
                                // éŸ³é¢‘æµæŒç»­è¿è¡Œï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç†
                            }
                        }
                    }
                    
                    "listen" -> {
                        // æœåŠ¡å™¨ç«¯ç›‘å¬æ§åˆ¶ï¼ˆä¸ESP32ä¸€è‡´ï¼‰
                        val state = json.optString("state")
                        when (state) {
                            "start" -> {
                                deviceState = DeviceState.LISTENING
                                Log.i(TAG, "ğŸ“¡ æœåŠ¡å™¨æŒ‡ç¤ºå¼€å§‹ç›‘å¬")
                            }
                            "stop" -> {
                                Log.i(TAG, "ğŸ“¡ æœåŠ¡å™¨æŒ‡ç¤ºåœæ­¢ç›‘å¬")
                                // ä¸æ‰‹åŠ¨åœæ­¢ï¼Œè®©æœåŠ¡å™¨ç«¯æ§åˆ¶
                            }
                        }
                    }
                }
            }
        }
    }
}
```

#### 1.2 æœåŠ¡å™¨ç«¯ä¼˜åŒ–
**ç›®æ ‡**ï¼šç¡®ä¿Androidç«¯å’ŒESP32ç«¯åœ¨æœåŠ¡å™¨ç«¯çš„å¤„ç†å®Œå…¨ä¸€è‡´

```python
# ä¿®æ”¹ receiveAudioHandle.py
async def handleAudioMessage(conn, audio):
    """
    ç»Ÿä¸€çš„éŸ³é¢‘å¤„ç†é€»è¾‘ - é€‚ç”¨äºESP32å’ŒAndroidç«¯
    """
    if not conn.asr_server_receive:
        return
    
    # ç»Ÿä¸€çš„VADæ£€æµ‹ï¼ˆESP32å’ŒAndroidå®Œå…¨ç›¸åŒï¼‰
    if conn.client_listen_mode == "auto":
        have_voice = conn.vad.is_vad(conn, audio)
    else:
        have_voice = conn.client_have_voice

    # ç»Ÿä¸€çš„éŸ³é¢‘ç´¯ç§¯é€»è¾‘
    if have_voice == False and conn.client_have_voice == False:
        conn.asr_audio.append(audio)
        conn.asr_audio = conn.asr_audio[-10:]  # ä¿ç•™æœ€æ–°10å¸§
        return
    
    conn.asr_audio.append(audio)
    
    # ç»Ÿä¸€çš„STTè§¦å‘é€»è¾‘
    if conn.client_voice_stop:
        conn.asr_server_receive = False
        
        if len(conn.asr_audio) < 15:
            conn.asr_server_receive = True
        else:
            # è°ƒç”¨ASRè¿›è¡Œè¯­éŸ³è¯†åˆ«
            text, error = await conn.asr.speech_to_text(conn.asr_audio, conn.session_id)
            
            if text and len(text.strip()) > 0:
                # å‘é€STTç»“æœåˆ°å®¢æˆ·ç«¯ï¼ˆESP32å’ŒAndroidç»Ÿä¸€å¤„ç†ï¼‰
                await send_stt_message(conn, text)
                await startToChat(conn, text)
            else:
                conn.asr_server_receive = True
        
        # æ¸…ç†çŠ¶æ€
        conn.asr_audio.clear()
        conn.reset_vad_states()

async def send_stt_message(conn, text):
    """
    ç»Ÿä¸€çš„STTç»“æœå‘é€ - ESP32å’ŒAndroidç«¯ç»Ÿä¸€æ¥æ”¶
    """
    stt_message = {
        "type": "stt",
        "text": text,
        "timestamp": time.time()
    }
    await conn.websocket.send(json.dumps(stt_message))
```

### æ–¹æ¡ˆ2ï¼šåè®®å±‚ç»Ÿä¸€ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰

#### 2.1 åˆ›å»ºç»Ÿä¸€çš„è®¾å¤‡æ¥å£
```kotlin
// åˆ›å»ºç»Ÿä¸€çš„è®¾å¤‡æŠ½è±¡
interface VoiceDevice {
    suspend fun startListening()
    suspend fun stopListening()
    suspend fun sendAudio(audioData: ByteArray)
    fun observeServerMessages(): Flow<ServerMessage>
}

// Androidç«¯å®ç°
class AndroidVoiceDevice(
    private val protocol: Protocol
) : VoiceDevice {
    override suspend fun startListening() {
        protocol.sendStartListening(ListeningMode.AUTO_STOP)
        // å¯åŠ¨çº¯éŸ³é¢‘æµ
        startPureAudioStream()
    }
    
    override suspend fun sendAudio(audioData: ByteArray) {
        protocol.sendAudio(audioData)
    }
    
    override fun observeServerMessages(): Flow<ServerMessage> {
        return protocol.incomingJsonFlow.map { json ->
            when (json.optString("type")) {
                "stt" -> ServerMessage.SttResult(json.optString("text"))
                "tts" -> ServerMessage.TtsState(json.optString("state"))
                else -> ServerMessage.Unknown
            }
        }
    }
}
```

## ğŸ”§ å®æ–½æ­¥éª¤

### ç¬¬ä¸€é˜¶æ®µï¼šAndroidç«¯ç®€åŒ–
1. **ç§»é™¤å®¢æˆ·ç«¯çŠ¶æ€ç®¡ç†é€»è¾‘**
   - åˆ é™¤`keepListening`ã€`isAudioFlowRunning`ç­‰å®¢æˆ·ç«¯çŠ¶æ€
   - ç®€åŒ–`startContinuousAudioFlow`ä¸ºçº¯éŸ³é¢‘å‘é€

2. **ç»Ÿä¸€éŸ³é¢‘æµç¨‹**
   - æ— æ¡ä»¶å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨
   - ç§»é™¤å®¢æˆ·ç«¯çš„VADå’ŒçŠ¶æ€åˆ¤æ–­é€»è¾‘

3. **ç®€åŒ–æ¶ˆæ¯å¤„ç†**
   - STTç»“æœä»…ç”¨äºUIå±•ç¤º
   - æ‰€æœ‰é€»è¾‘åˆ¤æ–­äº¤ç»™æœåŠ¡å™¨ç«¯

### ç¬¬äºŒé˜¶æ®µï¼šæœåŠ¡å™¨ç«¯ä¼˜åŒ–
1. **ç¡®ä¿å¤„ç†ä¸€è‡´æ€§**
   - éªŒè¯ESP32å’ŒAndroidç«¯åœ¨æœåŠ¡å™¨ç«¯çš„å¤„ç†è·¯å¾„å®Œå…¨ç›¸åŒ
   - ç»Ÿä¸€VADå‚æ•°å’ŒASRé…ç½®

2. **ä¼˜åŒ–å“åº”æœºåˆ¶**
   - ç¡®ä¿STTç»“æœå‘é€æ ¼å¼ç»Ÿä¸€
   - ä¼˜åŒ–TTSæ’­æ”¾çŠ¶æ€åŒæ­¥

### ç¬¬ä¸‰é˜¶æ®µï¼šæµ‹è¯•éªŒè¯
1. **è¡Œä¸ºä¸€è‡´æ€§æµ‹è¯•**
   - åŒä¸€æ®µè¯­éŸ³åœ¨ESP32å’ŒAndroidç«¯åº”äº§ç”Ÿç›¸åŒç»“æœ
   - è¯­éŸ³æ‰“æ–­æœºåˆ¶åº”å®Œå…¨ä¸€è‡´

2. **æ€§èƒ½å¯¹æ¯”**
   - å»¶è¿Ÿå¯¹æ¯”æµ‹è¯•
   - å‡†ç¡®ç‡å¯¹æ¯”æµ‹è¯•

## ğŸ¯ é¢„æœŸæ•ˆæœ

### ç»Ÿä¸€åçš„å®Œæ•´æµç¨‹
```mermaid
graph TB
    subgraph "å®¢æˆ·ç«¯å±‚ (ESP32/Android)"
        A[ç¡¬ä»¶/è½¯ä»¶éŸ³é¢‘é‡‡é›†] --> B[Opusç¼–ç ]
        B --> C[WebSocketå‘é€éŸ³é¢‘æ•°æ®]
    end
    
    subgraph "æœåŠ¡å™¨ç«¯ (ç»Ÿä¸€å¤„ç†)"
        C --> D[æ¥æ”¶éŸ³é¢‘æ•°æ®]
        D --> E[VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹]
        E --> F{æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ?}
        F -->|å¦| D
        F -->|æ˜¯| G[ASRè¯­éŸ³è¯†åˆ«]
        G --> H[STTç»“æœç”Ÿæˆ]
        H --> I[å‘é€STTç»“æœåˆ°å®¢æˆ·ç«¯]
        I --> J[å¯åŠ¨LLMå¯¹è¯]
        J --> K[TTSéŸ³é¢‘ç”Ÿæˆ]
        K --> L[å‘é€TTSéŸ³é¢‘åˆ°å®¢æˆ·ç«¯]
    end
    
    subgraph "å®¢æˆ·ç«¯å“åº”"
        I --> M[æ˜¾ç¤ºè¯†åˆ«æ–‡æœ¬]
        L --> N[æ’­æ”¾TTSéŸ³é¢‘]
        N --> A
    end
```

### ä¼˜åŠ¿åˆ†æ
- âœ… **å®Œå…¨ç»Ÿä¸€**: ESP32å’ŒAndroidç«¯è¡Œä¸ºå®Œå…¨ä¸€è‡´
- âœ… **ç®€åŒ–å®¢æˆ·ç«¯**: Androidç«¯é€»è¾‘å¤§å¹…ç®€åŒ–ï¼Œå‡å°‘bug
- âœ… **é›†ä¸­æ™ºèƒ½**: æ‰€æœ‰AIé€»è¾‘é›†ä¸­åœ¨æœåŠ¡å™¨ç«¯
- âœ… **æ˜“äºç»´æŠ¤**: åªéœ€è¦ç»´æŠ¤ä¸€å¥—æœåŠ¡å™¨ç«¯é€»è¾‘
- âœ… **æ€§èƒ½ä¼˜åŒ–**: å‡å°‘å®¢æˆ·ç«¯è®¡ç®—ï¼Œæå‡å“åº”é€Ÿåº¦

## ğŸ“ å®æ–½å»ºè®®

### ç«‹å³å¯è¡Œçš„æ”¹åŠ¨
1. **ä¿®æ”¹`ChatViewModel.kt`**ï¼š
   - ç§»é™¤`keepListening`çŠ¶æ€ç®¡ç†
   - ç®€åŒ–`startContinuousAudioFlow`é€»è¾‘
   - çº¯ç²¹çš„éŸ³é¢‘æ•°æ®å‘é€

2. **ä¼˜åŒ–æ¶ˆæ¯å¤„ç†**ï¼š
   - STTç»“æœä»…ç”¨äºUIæ›´æ–°
   - ç§»é™¤å¤æ‚çš„çŠ¶æ€åŒæ­¥é€»è¾‘

### æ¸è¿›å¼æ”¹è¿›
1. **ç¬¬ä¸€æ­¥**ï¼šåœ¨ç°æœ‰åŸºç¡€ä¸Šç§»é™¤ä¸å¿…è¦çš„å®¢æˆ·ç«¯é€»è¾‘
2. **ç¬¬äºŒæ­¥**ï¼šåˆ›å»ºç»Ÿä¸€çš„è®¾å¤‡æ¥å£æŠ½è±¡
3. **ç¬¬ä¸‰æ­¥**ï¼šå®Œå…¨é‡æ„ä¸ºçº¯æœåŠ¡å™¨ç«¯é©±åŠ¨æ¨¡å¼

è¿™ä¸ªæ–¹æ¡ˆæ˜¯å®Œå…¨å¯è¡Œçš„ï¼Œè€Œä¸”ä¼šå¤§å¤§ç®€åŒ–Androidç«¯çš„ä»£ç å¤æ‚åº¦ï¼Œè®©ä¸¤ç«¯çš„è¡Œä¸ºå®Œå…¨ä¸€è‡´ï¼ 